<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistics on Guangchuang YU</title>
    <link>http://guangchuangyu.github.io/categories/statistics/</link>
    <description>Recent content in Statistics on Guangchuang YU</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016 Guangchuang YU</copyright>
    <lastBuildDate>Sat, 28 Apr 2012 08:06:05 +0800</lastBuildDate>
    <atom:link href="http://guangchuangyu.github.io/categories/statistics/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>enrichment analysis</title>
      <link>http://guangchuangyu.github.io/post/stats/2012_enrichment-analysis/</link>
      <pubDate>Sat, 28 Apr 2012 08:06:05 +0800</pubDate>
      
      <guid>http://guangchuangyu.github.io/post/stats/2012_enrichment-analysis/</guid>
      <description>&lt;p&gt;经常看到一些饼图，描述某些事物的组成，比如说有钱人的学历分布，然后我们可以看到高学历所占比例并不高，根据这个比例下结论通常是错的，这些比例说明不了问题，如果把各种学历在总体人口中的分布做为背景进行考虑的话，你就会发现学历还是有点用的。
当我们用组学测定了一大堆分子之后，我们希望站在更高的角度去看这些分子和那些生物学过程相关。那么通常各种注释，对这些基因/蛋白进行分类，那么从分类的比例上，是不能草率下结论，正如上面有钱人学历分布的例子一样。我们需要把总体的分布考虑进去。
和某个注释/分类是否有相关性，把基因分成属于这一类，和不属于这一类两种，这就好比经典统计学中的白球和黑球的抽样问题。也可以列一个２x２的表，进行独立性分析。
以文章&lt;a href=&#34;http://cancerres.aacrjournals.org/content/62/16/4722&#34;&gt;Gene Expression in Ovarian Cancer Reflects Both Morphology and Biological Behavior, Distinguishing Clear Cell from Other Poor-Prognosis Ovarian Carcinomas&lt;/a&gt;所鉴定的差异基因为例。&lt;/p&gt;

&lt;p&gt;73个差异基因的Symbol，我把它转为 entrezgene
ID得到57个（漏掉的不管它，只是做为一个例子）:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; eg
 [1] &amp;quot;7980&amp;quot;   &amp;quot;3081&amp;quot;   &amp;quot;3162&amp;quot;   &amp;quot;3059&amp;quot;   &amp;quot;1545&amp;quot;   &amp;quot;1917&amp;quot;   &amp;quot;6696&amp;quot;   &amp;quot;5797&amp;quot;  
 [9] &amp;quot;6648&amp;quot;   &amp;quot;10397&amp;quot;  &amp;quot;6781&amp;quot;   &amp;quot;5817&amp;quot;   &amp;quot;1282&amp;quot;   &amp;quot;1284&amp;quot;   &amp;quot;6948&amp;quot;   &amp;quot;7077&amp;quot;  
[17] &amp;quot;5744&amp;quot;   &amp;quot;8566&amp;quot;   &amp;quot;1368&amp;quot;   &amp;quot;1474&amp;quot;   &amp;quot;11015&amp;quot;  &amp;quot;3306&amp;quot;   &amp;quot;728441&amp;quot; &amp;quot;2678&amp;quot;  
[25] &amp;quot;4286&amp;quot;   &amp;quot;3929&amp;quot;   &amp;quot;5095&amp;quot;   &amp;quot;2064&amp;quot;   &amp;quot;1428&amp;quot;   &amp;quot;6590&amp;quot;   &amp;quot;3569&amp;quot;   &amp;quot;2745&amp;quot;  
[33] &amp;quot;3912&amp;quot;   &amp;quot;978&amp;quot;    &amp;quot;5950&amp;quot;   &amp;quot;6539&amp;quot;   &amp;quot;9445&amp;quot;   &amp;quot;5004&amp;quot;   &amp;quot;9971&amp;quot;   &amp;quot;7453&amp;quot;  
[41] &amp;quot;2719&amp;quot;   &amp;quot;1410&amp;quot;   &amp;quot;1311&amp;quot;   &amp;quot;4653&amp;quot;   &amp;quot;4162&amp;quot;   &amp;quot;5358&amp;quot;   &amp;quot;3484&amp;quot;   &amp;quot;3486&amp;quot;  
[49] &amp;quot;2261&amp;quot;   &amp;quot;307&amp;quot;    &amp;quot;1672&amp;quot;   &amp;quot;4837&amp;quot;   &amp;quot;22795&amp;quot;  &amp;quot;486&amp;quot;    &amp;quot;4118&amp;quot;   &amp;quot;3915&amp;quot;  
[57] &amp;quot;10140&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面测试一下这些基因和化学刺激响应的相关性。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;goid &amp;lt;- “GO:0042221” # response to chemical stimulus
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;那么做为背景，总体基因为N，属于“化学刺激响应”这个分类的基因有M个。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;allgeneInCategory &amp;lt;- unique(get(goid, org.Hs.egGO2ALLEGS))
M &amp;lt;- length(allgeneInCategory)
N &amp;lt;- length(mappedkeys(org.Hs.egGO))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;样本的大小是n，属于“化学刺激响应”这个分类的基因有k个。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;n &amp;lt;- length(eg)
k &amp;lt;- sum(eg %in% allgeneInCategory)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;白球黑球问题，最简单的莫过于用二项式分布，从总体上看，要拿到一个基因属于“化学刺激响应”这个分类的概率是M/N。那么现在抽了n个基因，里面有k个基于这个分类，p值为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; 1-sum(sapply(0:k-1, function(i) choose(n,i) * (M/N)^i * (1-M/N)^(n-i)))
[1] 8.561432e-10
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;二项式分布，是有放回的抽样，你可以多次抽到同一基因，这是不符合的。所以这个计算只能说是做为近似的估计值，无放回的抽样，符合超几何分布，通过超几何分布的计算，p值为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; phyper(k-1,M, N-M, n, lower.tail=FALSE)
[1] 7.879194e-10
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果用2x2表做独立性分析，表如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; d &amp;lt;- data.frame(gene.not.interest=c(M-k, N-M-n+k), gene.in.interest=c(k, n-k))
&amp;gt; row.names(d) &amp;lt;- c(&amp;quot;In_category&amp;quot;, &amp;quot;not_in_category&amp;quot;)
&amp;gt; d
                gene.not.interest gene.in.interest
In_category                  2613               28
not_in_category             15310               29
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个也有很多方法可以做检验，经典的有卡方检验和fisher&amp;rsquo;s exact test。
如果用卡方检验来做。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; chisq.test(d, )

    Pearson&#39;s Chi-squared test with Yates&#39; continuity correction

data:  d 
X-squared = 51.3849, df = 1, p-value = 7.592e-13
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对于２x２表来说，卡方检验通常也只能做为近似估计值，特别是当sample
size或expected all count比较小的时候，计算并不准确。 fisher&amp;rsquo;s exact
test，名副其实，真的就比较exact，因为它使用的是超几何分布来计算p值。这也是为什么fisher&amp;rsquo;s
exact test和超几何模式计算的p-值是一样的，&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; fisher.test(d)

    Fisher&#39;s Exact Test for Count Data

data:  d 
p-value = 7.879e-10
alternative hypothesis: true odds ratio is not equal to 1 
95 percent confidence interval:
 0.1013210 0.3089718 
sample estimates:
odds ratio 
 0.1767937 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;通常各种软件做GO富集性分析，都是使用超几何分布进行计算。
IPA软件则是使用fisher&amp;rsquo;s exact test来检验基因在某个网络中是否富集。
从这个例子上看，chi-squared
test的表现最差，binomial做为p值的近似估计还是不错的，因为计算较为简单。
富集性分析应用范围非常广，从&lt;a href=&#34;http://bioconductor.org/packages/devel/bioc/html/DOSE.html&#34;&gt;Disease Ontology&lt;/a&gt;,
&lt;a href=&#34;http://bioconductor.org/packages/devel/bioc/html/clusterProfiler.html&#34;&gt;Gene Ontology, KEGG&lt;/a&gt;,
到&lt;a href=&#34;http://bioconductor.org/packages/devel/bioc/html/ReactomePA.html&#34;&gt;Reactome Pathway&lt;/a&gt;等等。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Support Vector Machine</title>
      <link>http://guangchuangyu.github.io/post/math/2012_support-vector-machine/</link>
      <pubDate>Thu, 12 Apr 2012 05:37:55 +0800</pubDate>
      
      <guid>http://guangchuangyu.github.io/post/math/2012_support-vector-machine/</guid>
      <description>&lt;p&gt;支持向量机(Support Vector Machines, SVM)最初由Vladimir
Vapnik于1997年提出，SVM最简单的形式就是找出一下区分界限（descision
boundary），也称之为超平面(hyperplane)，使得离它最近的点（称之为support
vectors）与之间隔最大。
&lt;img src=&#34;http://guangchuangyu.github.io/blog_images/2012/04/linearSVM.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这和logistic regression有些相似，区别在于logistic
regression要求所有的点尽可能地远离中间那条线，而SVM是要求最接近中间线的点尽可能地远离中间线。也就是说SVM的主要目标是区分那些最难区分的点。&lt;/p&gt;

&lt;p&gt;SVM对于hyperplane的定义，在形式上和logistic regression一样,logistic
regression的decision boundary由$\theta^TX=0$确定,SVM则用$w^TX+b=0$表示,其中b相当于logistic regression中的$\theta_0$，从形式上看，两者并无区别，当然如前面所说，两者的目标不一样，logistic regression着眼于全局，SVM着眼于support
vectors。有监督算法都有label变量y，logistic
regression取值是&lt;code&gt;{0,1}&lt;/code&gt;，而SVM为了计算距离方便，取值为&lt;code&gt;{-1,1}&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;那么SVM的问题就变成为，确定参数w和b，以满足： $w^T x_i + b \ge
+1$ when $y_i = +1$ $w^T x_i + b \le +1$ when
$ y_i = -1$
对于上图中最简单的例子，中间线可以由Ax+By+c=0表示，图上一个$(x_0, y_0)$的点到中间线的距离为$\frac{|Ax_0+By_0+c|}{\sqrt{A^2+B^2}}$。&lt;/p&gt;

&lt;p&gt;对于更高维的空间，点到hyperplane上的距离也是一样计算，定义为： $\frac{|w^Tx+b|}{||w||}=\frac{1}{||w||}$。
要距离最大，也就是求||w||的最小值。 那么问题就相当于在给定条件g(x):
$y_i(w^Tx_i)-b \ge 1$下，求f(x): $\frac{1}{2}||w||^2$的最大值。
这是一个限定条件下的优化问题，可以通过&lt;a href=&#34;http://en.wikipedia.org/wiki/Lagrange_multiplier&#34;&gt;Lagrange multiplier&lt;/a&gt;解决。&lt;/p&gt;

&lt;p&gt;这里，拉格朗日公式为： $L=\frac{1}{2}||w||^2-\sum{\alpha_i[y_i(w^Tx_i+b)-1]}$&lt;/p&gt;

&lt;p&gt;通过对拉格朗日公式的分析，问题变为： 给定$\alpha \ge 0$
$\sum{\alpha_iy_i} = 0$ 求$\sum{\alpha_i} -
\frac{1}{2}\sum{\alpha_i\alpha_jy_iy_jx_ix_j}$的最大值。&lt;/p&gt;

&lt;p&gt;对于$\alpha$值，通常训练算法还通过C参数进行限制$C \ge
\alpha \ge 0$，这个参数相当于logistic regression里的$\lambda$参数，对outlier数据点的penalty。&lt;/p&gt;

&lt;p&gt;通过Sequential Minimal Optimization（SMO）算法，可以快速地给出解。&lt;/p&gt;

&lt;p&gt;对于无法进行线性区分的数据，需要进行transformation，把数据映射到另一个空间里，使之可以线性区分，这就是kernel
function所干的事情。&lt;/p&gt;

&lt;p&gt;参考了《machine learning in
action》和ml-class的材料后，我在&lt;a href=&#34;https://github.com/GuangchuangYu/mlass&#34;&gt;mlass&lt;/a&gt;包里实现了简化版本的SMO算法。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;require(mlass)
data(ex6data2)
model &amp;lt;- svmTrain(X,y, C=1, kernelFunction=&amp;quot;gaussianKernel&amp;quot;)
plot(model, X,y, type=&amp;quot;nonlinear&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://guangchuangyu.github.io/blog_images/2012/04/Screen-Shot-2012-04-10-at-3.09.43-PM.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Five things biologists should know about statistics</title>
      <link>http://guangchuangyu.github.io/post/stats/2011_five-things-biologists-should-know-about-statistics/</link>
      <pubDate>Fri, 24 Jun 2011 06:10:37 +0800</pubDate>
      
      <guid>http://guangchuangyu.github.io/post/stats/2011_five-things-biologists-should-know-about-statistics/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.ebi.ac.uk/~birney/&#34;&gt;Ewan Birney&lt;/a&gt;最近的一篇博文（&lt;a href=&#34;http://genomeinformatician.blogspot.com/2011/06/five-statistical-things-i-wished-i-had.html&#34;&gt;Five statistical things I wished I had been taught 20 years ago&lt;/a&gt;
）讲述了统计对于生物学的重要性。&lt;/p&gt;

&lt;p&gt;一开始从RA
Fisher讲起，说生物压根就是统计。Fisher是个农业学家，他所建立的那些统计方法，都是从生物学问题出发。&lt;/p&gt;

&lt;p&gt;Ewan所谈及的五个方面分别是：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;1. Non parametric statistics. These are statistical tests which make a
bare minimum of assumptions of underlying distributions; in biology we
are rarely confident that we know the underlying distribution, and hand
waving about central limit theorem can only get you so far. Wherever
possible you should use a non parameteric test. This is Mann-Whitney (or
Wilcoxon if you prefer) for testing &amp;ldquo;medians&amp;rdquo; (Medians is in quotes
because this is not quite true. They test something which is closely
related to the median) of two distributions, Spearman&amp;rsquo;s Rho (rather
pearson&amp;rsquo;s r2) for correlation, and the Kruskal test rather than ANOVAs
(though if I get this right, you can&amp;rsquo;t in Kruskal do the more
sophisticated nested models you can do with ANOVA). Finally, don&amp;rsquo;t
forget the rather wonderful Kolmogorov-Smirnov (I always think it sounds
like really good vodka) test of whether two sets of observations come
from the same distribution. All of these methods have a basic theme of
doing things on the rank of items in a distribution, not the actual
level. So - if in doubt, do things on the rank of metric, rather than
the metric itself.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;学校里教统计，多半是t检验和ANOVA，这些方法都有assumption需要满足，比如正态分布啥的。多半大家是默认它满足，然后就开始套着用，这是比较危险的，如果assumption不满足，或者数据中有outliers，都可能会导致错误的结论。&lt;/p&gt;

&lt;p&gt;今年&lt;a href=&#34;http://guangchuangyu.github.io/2010/11/phosphoproteome-profile-of-human-lung-cancer-cell-line-a549/&#34;&gt;磷酸化谱的文章&lt;/a&gt;，用到了免疫组化，实验结果的量化是由医生给出来打分值，癌组织和癌旁组织两组数据，免疫组化的数据不可能用参数统计，这个结果我就是用Wilcoxon
signed rank test去做检验。文中所提出的其它非参统计方法，全都不会。囧&lt;/p&gt;

&lt;p&gt;关于相关性，这里有篇文章，比较了Pearson和Spearman： &lt;a href=&#34;http://www.jstor.org/stable/2346598&#34;&gt;On the Effects of
Non-Normality on the Distribution of the Sample Product-Moment
Correlation Coefficient&lt;/a&gt; (Kowalski,
1975)&lt;/p&gt;

&lt;p&gt;还有文章说用Kendall&amp;rsquo;s tau比Spearman&amp;rsquo;s Rho要好： Newson R. &lt;a href=&#34;http://www.stata-journal.com/sjpdf.html?articlenum=st0007&#34;&gt;Parameters
behind &amp;ldquo;nonparametric&amp;rdquo; statistics: Kendall&amp;rsquo;s tau,Somers&amp;rsquo; D and median
differences&lt;/a&gt;.
Stata Journal 2002; 2(1):45-64.&lt;/p&gt;

&lt;p&gt;虽然作者强调非参统计，但是如果数据分布满足参数统计的assumption的话，还是用参数统计好，更加powerful。这个可能需要我们在做统计之前对数据分布做一下检验。不过正态检验其实用处也不大，小样本的话，不够powerful，大样本的话，即使不是正态分布，t-test和ANOVA也是很robust的。&lt;/p&gt;

&lt;p&gt;如果不满足参数统计检验的话，也不一定就得用非参统计，不负责任地说，可能用&lt;a href=&#34;http://guangchuangyu.github.io/2009/07/bootstrap-method/&#34;&gt;bootstrap&lt;/a&gt;效果还更好。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;2. R (or I guess S). R is a cranky, odd statistical language/system with
a great scientific plotting package. Its a package written mainly by
statisticians for statisticians, and is rather unforgiving the first
time you use it. It is defnitely worth persevering. It&amp;rsquo;s basically a
combination of excel spreadsheets on steriods (with no data entry. an
Rdata frame is really the same logical set as a excel workbook - able to
handle millions of points, not 1,000s), a statistical methods compendium
(it&amp;rsquo;s usually the case that statistical methods are written first in R,
and you can almost guarantee that there are no bugs in the major
functions - unlike many other scenarios) and a graphical data
exploration tool (in particular lattice and ggplot packages). The syntax
is inconsistent, the documentation sometimes wonderful, often awful and
the learning curve is like the face of the Eiger. But once you&amp;rsquo;ve met
p.adjust(), xyplot() and apply(), you can never turn back.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;http://www.r-project.org&#34;&gt;R&lt;/a&gt;实在是太好用了，习惯用矢量运算之后，我就很少用perl了。不过学生物的，我所见过的人，能用好excel的人不多（我也不会用-,-），会用SPSS的人非常少，SAS从没见过有人用。每次我告诉身边的人，我用的是R，几乎都没人听说过的。在国内，目前主要也就高校里有人用。但至少做生信的，是需要学R的，&lt;a href=&#34;http://www.bioconductor.org/&#34;&gt;Bioconductor&lt;/a&gt;上面那一大堆的软件包，已然是无法回避。&lt;/p&gt;

&lt;p&gt;学生物的人都喜欢有图形界面的软件，像spss这种，点菜单无非是为了选参数，而R这种，变成敲键盘而已，一样的。用编程语言比用分析软件要好，可自动化，而且有利于交流（看一下代码，就知道都干了些什么），像SPSS这种把很多分析模块化，点点鼠标就能把回归模型算出来，固然是好，但是现代的数据分析，已经很少有问题是点个鼠标就能解决的了。&lt;/p&gt;

&lt;p&gt;至于画图，文中提到lattice和ggplot，lattice应该是目前R上面最复杂的图形包，功能比ggplot要强得多，画图速度也比ggplot要快，不过我没用过。只学了ggplot，因为ggplot的语法更加human
friendly，我觉得，学了ggplot后，都会爱上画图的 =,=&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;3. The problem of multiple testing, and how to handle it, either with
the Expected value, or FDR, and the backstop of many of piece of
bioinformatics - large scale permutation. Large scale permutation is
sometimes frowned upon by more maths/distribution purists but often is
the only way to get a sensible sense of whether something is likely &amp;ldquo;by
chance&amp;rdquo; (whatever the latter phrase means - it&amp;rsquo;s a very open question)
given the complex, hetreogenous data we have. 10 years ago perhaps the
lack of large scale compute resources meant this option was less open to
people, but these days basically everyone should be working out how to
appropriate permute the data to allow a good estimate of
&amp;ldquo;surprisingness&amp;rdquo; of an observation.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;高通量的组学数据，变得越来越常见，pvalue算的是犯一类错误的概率，组学数据观测点多，而重复少，noise很多，如果单纯卡个pvalue，越高通量的数据，犯二类错误的概率会更大，假阳性没有得到控制。这个越来越重要，这周去给学生上课，我还专门讲了Bonferroni
Method、Benjamini-Hochberg
Method还有q-value，不过好像我讲的时候，学生都没啥兴趣，或许有一天，他们写文章，reviewer要求给出FDR的时候，希望还能记起。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;4. The relationship between Pvalue, Effect size, and Sample size This
needs to be drilled into everyone - we&amp;rsquo;re far too trigger happy quoting
Pvalues, when we should often be quoting Pvalues and Effect size. Once a
Pvalue is significant, it&amp;rsquo;s higher significance is sort of meaningless
(or rather it compounds Effect size things with Sample size things, the
latter often being about relative frequency). So - if something is
significantly correlated/different, then you want to know about how much
of an effect this observation has. This is not just about GWAS like
statistics - in genomic biology we&amp;rsquo;re all too happy about quoting some
small Pvalue not realising that with a million or so points often, even
very small deviations will be significant. Quote your r2, Rhos or
proportion of variance explained&amp;hellip;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;从没接触过GWAS，不知道是怎么算的，从文中的描述看，这里讲的是power
analysis，这个对实验设计有用，可以估计sample size。当然如果sample
size已确定，那么设定pvalue和power，可以计算effect
size，就是说，实验可以detect出多大的effect。或者知道sample size,effect
size,
pvalue，可以计算power，就是说effect存在的话，有多大的概率可以detect出来。这和pvalue不一样，pvalue算的是没有effect（$H_0$）的概率。&lt;/p&gt;

&lt;p&gt;power analysis就是四个变量，颠来倒去，知道三个，算第四个。&lt;/p&gt;

&lt;p&gt;差异越大，越容易检测出来，样本间的variance越大，就需要更大的样本量，来排除样本间差异所带来的干扰。差不多就是这样一些东西。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;5. Linear models and PCA. There is a tendency often to jump to quite
complex models - networks, or biologically inspired combinations, when
our first instinct should be to crack out the well established lm()
(linear model) for prediction and princomp() (PCA) for dimensionality
reduction. These are old school techniques - and often if you want to
talk about statistical fits one needs to make gaussian assumptions about
distributions - but most of the things we do could be either done well
in a linear model, and most of the correlation we look at could have
been found with a PCA biplot. The fact that these are 1970s bits of
statistics doesn&amp;rsquo;t mean they don&amp;rsquo;t work well.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;PCA就是把高维空间映射到低维空间，在保留尽可能多信息的情况下进行降维处理，
下面这段解释了linear model和PCA之间的不同之处：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;One may also see PCA as an analogue of the least squares method to
find a line that goes as “near” the points as possible – to simplify,
let us assume there are just two dimensions. But while the least
squares method is asymetric (the two variables play different roles:
they are not interchangeable, we try to predict one from the others,
we measure the distance parallel to one coordinate axis), the PCA is
symetric (the distance is measured orthogonally to the line we are
looking for).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;John Mark在评论里写道，进阶还需要学什么，一并记录下来。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The next level - number 6 - would be to get beyond P values, and
instead compute probability distributions of the quantities of
interest. This leads naturally to number 7, which is to delve into the
generative models that are currently solved by MCMC methods. This is
basically the Bayesian approach. Just as an aside &amp;ldquo;non parametrics&amp;rdquo; in
some new work is also used to mean models where the number of
parameters varies, as a consequence of the method.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Bootstrap Method</title>
      <link>http://guangchuangyu.github.io/post/stats/2009_bootstrap-method/</link>
      <pubDate>Fri, 31 Jul 2009 09:14:42 +0800</pubDate>
      
      <guid>http://guangchuangyu.github.io/post/stats/2009_bootstrap-method/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Bootstrapping_(statistics)&#34;&gt;bootstrap&lt;/a&gt;是对观测数据集进行有放回（replacement）的随机抽样，以评估总体的各项统计指标。可以用于假设检验、参数估计。好处是并不要求大样本，也不要求正态数据，并且对于不同的统计指标使用的是同样的计算方法。结果也更为可靠，坏处是计算量大。&lt;/p&gt;

&lt;p&gt;统计推断(statistical
inference)是基于样本统计值的抽样分布来计算的，抽样分布需要从总体中许多的样本来计算，在只有一个样本的情况下，bootstrap对这一随机样本进行有放回的重复抽样，每一个重抽样本与原始随机样本一样大，每次计算相应的抽样的统计值，重复了N次之后，就可以计算统计值的bootstrap分布。&lt;/p&gt;

&lt;p&gt;下面做一个小小的试验：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a &amp;lt;- c(seq(1:10), rnorm(50))  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;#创建一个样本，60个数据，非正态分布的，如下图&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://guangchuangyu.github.io/blog_images/2009/07/sample_a.png&#34; alt=&#34;&#34; title=&#34;sample_a&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;b &amp;lt;- rep(0, 1000)
for (i in 1:1000) {
    b[i] &amp;lt;- mean(sample(a, replace=TRUE))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对它进行1000次有放回重复抽样，计算均值，均值分布的柱状图和qq图如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://guangchuangyu.github.io/blog_images/2009/07/hist_qq.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;分布是正态的。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; mean(a)    #样本均值
[1] 0.947186
&amp;gt; mean(b)   #重抽样1000个样本均值的均值
[1] 0.9358049
&amp;gt; sd(b)
[1] 0.3245479
&amp;gt; sd(a)/sqrt(60)
[1] 0.3318863
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由bootstrap方法得到的标准误是0.325，而由原先随机样本所估算的是0.332，两者是相当接近的。由此可见呢，bootstrap方法与理论上的从总体中抽样所得到的样本分布是一致的，这样子就可以基于一个样本来计算样本的分布，而不是要从总体中抽N个样本。&lt;/p&gt;

&lt;p&gt;还用上面的例子，使用样本均值$ \bar{x}$去估算总体的均值$
\mu$，虽然我们的样本不是正态的，但如果bootstrap
distribution是正态的话，就可以使用类似于单样本t置信区间（要求样本是正态的）的公式:$
\bar{x} \pm t \cdot SE = \bar{x} \pm t \cdot
\frac{s}{\sqrt{n}}$ 相应的bootstrap t置信区间是：$ statistic
\pm t \cdot SE_{boot}$ 上面例子，总体均值$ \mu$
95%的置信度，就会落在：$ mean(a) \pm 2.009 \cdot sd(b)$
可以使用它，计算所有统计指标的置信区间。&lt;/p&gt;

&lt;p&gt;用于层次聚类分析的一个例子，使用Pvclust这个包，用于层次聚类，并通过multiscale
bootstrap
resampling给出相应的&lt;em&gt;p&lt;/em&gt;-value用于评估聚类结果的不确定性。提供了两种&lt;em&gt;p&lt;/em&gt;-values，AU（approximately
unbiased p-value, 通过multiscale bootstrap
resampling计算）和BP（bootstrap probability, 通过normal bootstrap
resampling计算），AU比BP较为unbiased。
Pvclust使用*hclust*（来自于stats包）进行层次聚类，并自动计算所有的子类的&lt;em&gt;p&lt;/em&gt;-value。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(pvclust)  # loads package
a &amp;lt;- matrix(rnorm(1000), 100, 10, dimnames=list(paste(&amp;quot;g&amp;quot;, 1:100, sep=&amp;quot;&amp;quot;), paste(&amp;quot;t&amp;quot;,1:10, sep=&amp;quot;&amp;quot;)))  # creats sample data
at &amp;lt;- t(a)  # transposes of a
cl &amp;lt;- pvclust(at, nboot=1000)  #performs hierarchical cluster analysis with multiscale bootstrap with 1000 repetitions.
pvrect(cl, alpha=0.95)  #highlights with red rectangles all clusters in the dendrogram which have an AU value above 95%, AU p-value &amp;gt; 0.95, the hypothesis that &amp;quot;the cluster does not exist&amp;quot; is rejected with significance level 0.05;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://guangchuangyu.github.io/blog_images/2009/07/pvclust_test.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#pick significant clusters.
clsig &amp;lt;- pvpick(cl, alpha=0.95, pv=&amp;quot;au&amp;quot;, type=&amp;quot;geq&amp;quot;, max.only=TRUE)  
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;reference:5129f3fc49180ee68d0efdb6ded483c8&#34;&gt;Reference&lt;/h3&gt;

&lt;p&gt;1.  Moore, D.S., McCabe, G.P. &amp;amp; Craig, B. Introduction to the Practice
of Statistics w/CD-ROM.  (W. H. Freeman: 2007).&lt;/p&gt;

&lt;p&gt;2.  Suzuki, R. (2006). Pvclust: an R package for assessing the uncertainty in hierarchical clustering, Bioinformatics, 22(12), 1540-1542
DOI:
&lt;a href=&#34;http://dx.doi.org/10.1093/bioinformatics/btl117&#34;&gt;10.1093/bioinformatics/btl117&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
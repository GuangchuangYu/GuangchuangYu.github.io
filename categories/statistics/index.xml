<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistics on Guangchuang Yu</title>
    <link>https://guangchuangyu.github.io/categories/statistics/</link>
    <description>Recent content in Statistics on Guangchuang Yu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 14 Mar 2019 12:37:55 +0800</lastBuildDate>
    
	<atom:link href="https://guangchuangyu.github.io/categories/statistics/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>欧式距离如何应对缺失值</title>
      <link>https://guangchuangyu.github.io/2019/03/euclidean-distance-with-na-values/</link>
      <pubDate>Thu, 14 Mar 2019 12:37:55 +0800</pubDate>
      
      <guid>https://guangchuangyu.github.io/2019/03/euclidean-distance-with-na-values/</guid>
      <description>&lt;p&gt;biobabble作者群有一个小伙伴提出来的问题。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;没错，凡是给biobabble投稿的小伙伴都会被拉入作者群。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;话说有一个矩阵，我们让它某个值缺失，算出来的距离和原来的竟然是一样的：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;&amp;gt; dat = matrix(1:10, 2)
&amp;gt; dist(dat)
         1
2 2.236068
&amp;gt; dat[1,1] = NA
&amp;gt; dist(dat)
         1
2 2.236068
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这有点反直觉，实际上你再搞个缺失值，它算出来还是一样的：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; dat[1,3] = NA
&amp;gt; dist(dat)
         1
2 2.236068
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;但以我的经验，我通常不敢轻易说人家有bug，我们得确认一下。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>unknown annotation in enrichment analysis</title>
      <link>https://guangchuangyu.github.io/2017/03/unknown-annotation-in-enrichment-analysis/</link>
      <pubDate>Fri, 03 Mar 2017 00:10:37 +0800</pubDate>
      
      <guid>https://guangchuangyu.github.io/2017/03/unknown-annotation-in-enrichment-analysis/</guid>
      <description>&lt;p&gt;小伙伴说注释不全，比如KEGG只有不到1万个基因有注释，但他一次RNA-seq出来的基因有2万多个，那其它没注释那1万多个岂不是扔了？！就某个通路来说，两种情况，要么属于，要么不属于这个通路。那1万多个应该放在背景里，不要扔。&lt;/p&gt;

&lt;p&gt;我的解答是三种情况，1属于，2不属于，3不知道。对于缺失信息的，当然是扔。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>主成分分析</title>
      <link>https://guangchuangyu.github.io/2014/07/principle_component_analysis/</link>
      <pubDate>Tue, 15 Jul 2014 11:37:55 +0800</pubDate>
      
      <guid>https://guangchuangyu.github.io/2014/07/principle_component_analysis/</guid>
      <description>&lt;p&gt;使用《Bioinformatics and Molecular Evolution》Table 2.2 (page 24)中的数据:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; aa
  VOL  BULK POLARITY    PI HYD1  HYD2 SURFACE_AREA FRACT_AREA
A  67 11.50     0.00  6.00  1.8   1.6          113       0.74
R 148 14.28    52.00 10.76 -4.5 -12.3          241       0.64
N  96 12.28     3.38  5.41 -3.5  -4.8          158       0.63
D  91 11.68    49.70  2.77 -3.5  -9.2          151       0.62
C  86 13.46     1.48  5.05  2.5   2.0          140       0.91
Q 114 14.45     3.53  5.65 -3.5  -4.1          189       0.62
E 109 13.57    49.90  3.22 -3.5  -8.2          183       0.62
G  48  3.40     0.00  5.97 -0.4   1.0           85       0.72
H 118 13.69    51.60  7.59 -3.2  -3.0          194       0.78
I 124 21.40     0.13  6.02  4.5   3.1          182       0.88
L 124 21.40     0.13  5.98  3.8   2.8          180       0.85
K 135 15.71    49.50  9.74 -3.9  -8.8          211       0.52
M 124 16.25     1.43  5.74  1.9   3.4          204       0.85
F 135 19.80     0.35  5.48  2.8   3.7          218       0.88
P  90 17.43     1.58  6.30 -1.6  -0.2          143       0.64
S  73  9.47     1.67  5.68 -0.8   0.6          122       0.66
T  93 15.77     1.66  5.66 -0.7   1.2          146       0.70
W 163 21.67     2.10  5.89 -0.9   1.9          259       0.85
Y 141 18.03     1.61  5.66 -1.3  -0.7          229       0.76
V 105 21.57     0.13  5.96  4.2   2.6          160       0.85
&amp;gt; aa.pc=prcomp(aa, center=TRUE, scale.=TRUE)
&amp;gt; aa.pc
Standard deviations:
[1] 1.88954924 1.67729608 0.88574923 0.65278312 0.53130822 0.27233782 0.21394709
[8] 0.05808934

Rotation:
                     PC1         PC2           PC3         PC4        PC5
VOL           0.05790316 -0.58494270  0.1057571970 -0.09311996  0.1684497
BULK         -0.22089815 -0.48085679  0.1685873871 -0.15647005 -0.6842181
POLARITY      0.44390146 -0.10372198  0.1432388489  0.73088587 -0.1747201
PI            0.18580066 -0.25244261 -0.9417631776  0.02722752 -0.0522075
HYD1         -0.49279466 -0.03284274 -0.1281013177  0.35033569 -0.3534423
HYD2         -0.50821923  0.03312719 -0.1292531953 -0.12776013  0.1837842
SURFACE_AREA  0.10045084 -0.56587879  0.1408585179 -0.10640314  0.3652725
FRACT_AREA   -0.45283231 -0.17244828  0.0009997326  0.53059489  0.4220135
                     PC6         PC7          PC8
VOL          -0.11705506  0.21351836 -0.739571539
BULK          0.25124136 -0.35181704  0.109655303
POLARITY      0.39252691  0.22974777  0.009653888
PI            0.04562347 -0.09136074  0.030622127
HYD1         -0.50083501  0.48686655  0.064292387
HYD2          0.70974650  0.41191312 -0.019940539
SURFACE_AREA -0.11107422  0.24097250  0.659316956
FRACT_AREA   -0.01018472 -0.55201871 -0.027363410
&amp;gt; summary(aa.pc)
Importance of components:
                          PC1    PC2     PC3     PC4     PC5     PC6     PC7
Standard deviation     1.8895 1.6773 0.88575 0.65278 0.53131 0.27234 0.21395
Proportion of Variance 0.4463 0.3517 0.09807 0.05327 0.03529 0.00927 0.00572
Cumulative Proportion  0.4463 0.7980 0.89603 0.94930 0.98459 0.99386 0.99958
                           PC8
Standard deviation     0.05809
Proportion of Variance 0.00042
Cumulative Proportion  1.00000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;PC1和PC2能够解释79.8%的variation。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>什么是T 检验</title>
      <link>https://guangchuangyu.github.io/2012/05/%E4%BB%80%E4%B9%88%E6%98%AFt-%E6%A3%80%E9%AA%8C/</link>
      <pubDate>Tue, 29 May 2012 06:17:56 +0800</pubDate>
      
      <guid>https://guangchuangyu.github.io/2012/05/%E4%BB%80%E4%B9%88%E6%98%AFt-%E6%A3%80%E9%AA%8C/</guid>
      <description>跟某同学讲了T test之后，整理一下。
很多的检验和我们的直觉是一致的，前阵子在一个群里，有管理学院的人问说想看两个样本是不是来自于同一个分布，我叫他画两个CDF，一看就知道。对方说不要看图，我就让他用Kolmogorov-Smirnov Tests。我自己搜了一下，发现ks.test检验的就是拿两个CDF的距离做为统计量，虽然计算很复杂，但是和intuition那是相当一致啊。
最简单也最常用的，莫过于T检验，用我们的直觉就可以理解了，但是我发现不理解还有用错的人也挺多的。
我们要看一个样本的均值是不是等于0，最naive的办法就是看样本的均值和0差别多大。
这个比较之所以naive，因为没有考虑到数据的分布，从上图的两个populations来看，它们的均值都是0，从绿色的分布中抽到一个均值为3的样本，概率并不小，但是从红色的分布中得到这样一个样本，那就是小概率事件。所以不能单纯比较均值，而是要看均值的分布，从上面的populations上看，和数据的离散程度有关。 我们随机抽取100个sample，得到以下的均值分布：
我们需要对均值的离散程度做penalty，那么就可以考虑这样一个统计量mean(x)/SEM, SEM代表standard error of the mean，那么这个统计量比单纯的均值要科学得多。这个统计量，就是学生氏所定义的t。
如果没有大量的样本，是没办法估计SEM的，但是从上面两个图上看，样本间均值的标准误SEM，和总体数据的标准误是正相关的。而总体的标准误可以用样本的标准误,sd(x),来估计。如果我们考虑最简单的形式呢？定义统计量mean(x)/sd(x)。
那么，请等一下，我们还需要考虑到样本量的影响，如果sample size没有影响，那么我们就不需要采集大样本了。从我们的直觉上看，肯定是样本量越大，对总体参数的估计越准确了。
从图上看，还是和直觉很一致。sample size越大，分布越compact，对总体均值的估计也就越准确。那么就需要使用sample size进行加权，把统计量修改为mean(x)/sd(x) * f(n)，其中n为sample size。
我们可以想像，学生氏当年try了几种形式的f(n)，发现sqrt(n)效果最好。于是他就定义了统计量: t = mean(x)/(sd(x)/sqrt(n))。 sqrt(n)效果好，因为sd(x)/sqrt(n)正好是对样本间均值标准误SEM的估计。
我们又可以想像，学生氏当年收集了很多个样本，计算了多个t值，发现这些t值的分布是有规律的，有点像正态分布，学生氏把它定义为t分布，利用t分布的probability density function，就可以计算p-value啦。
上图就是从标准正态分布里抽取100个样本，所计算的t值分布。
很多人上课学不懂，我觉得是因为一上来告诉你t怎么算，但是没让你理解SEM，SEM是理解t值计算的关键。
算完t之后，一句话，符合t分布，然后就是查表看p值,或者让计算机算，太抽象，这世界本来没有t分布，是学生氏定义了t统计量，并发现符合某分布，把它定义为t分布，有计算机做simulation，重现这个过程，就不抽象了，也就好理解了。
至于两样本，如果是paired的话，那就是paired之间相减，用差值做单样本t检验。如果不是成对，那就是t=(mean(x1)-mean(x2))/SEDM.
其中SEDM代表standard error of difference of means，这里有一个pool与否的问题，SEDM看上去稍微复杂了一点点，但是basic idea是一样的，非常好理解。</description>
    </item>
    
    <item>
      <title>enrichment analysis</title>
      <link>https://guangchuangyu.github.io/2012/04/enrichment-analysis/</link>
      <pubDate>Sat, 28 Apr 2012 08:06:05 +0800</pubDate>
      
      <guid>https://guangchuangyu.github.io/2012/04/enrichment-analysis/</guid>
      <description>&lt;p&gt;经常看到一些饼图，描述某些事物的组成，比如说有钱人的学历分布，然后我们可以看到高学历所占比例并不高，根据这个比例下结论通常是错的，这些比例说明不了问题，如果把各种学历在总体人口中的分布做为背景进行考虑的话，你就会发现学历还是有点用的。
当我们用组学测定了一大堆分子之后，我们希望站在更高的角度去看这些分子和那些生物学过程相关。那么通常各种注释，对这些基因/蛋白进行分类，那么从分类的比例上，是不能草率下结论，正如上面有钱人学历分布的例子一样。我们需要把总体的分布考虑进去。
和某个注释/分类是否有相关性，把基因分成属于这一类，和不属于这一类两种，这就好比经典统计学中的白球和黑球的抽样问题。也可以列一个２x２的表，进行独立性分析。
以文章&lt;a href=&#34;http://cancerres.aacrjournals.org/content/62/16/4722&#34;&gt;Gene Expression in Ovarian Cancer Reflects Both Morphology and Biological Behavior, Distinguishing Clear Cell from Other Poor-Prognosis Ovarian Carcinomas&lt;/a&gt;所鉴定的差异基因为例。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Support Vector Machine</title>
      <link>https://guangchuangyu.github.io/2012/04/support-vector-machine/</link>
      <pubDate>Thu, 12 Apr 2012 05:37:55 +0800</pubDate>
      
      <guid>https://guangchuangyu.github.io/2012/04/support-vector-machine/</guid>
      <description>&lt;p&gt;支持向量机(Support Vector Machines, SVM)最初由Vladimir
Vapnik于1997年提出，SVM最简单的形式就是找出一下区分界限（descision
boundary），也称之为超平面(hyperplane)，使得离它最近的点（称之为support
vectors）与之间隔最大。
&lt;img src=&#34;http://guangchuangyu.github.io/blog_images/2012/04/linearSVM.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这和logistic regression有些相似，区别在于logistic
regression要求所有的点尽可能地远离中间那条线，而SVM是要求最接近中间线的点尽可能地远离中间线。也就是说SVM的主要目标是区分那些最难区分的点。&lt;/p&gt;

&lt;p&gt;SVM对于hyperplane的定义，在形式上和logistic regression一样,logistic
regression的decision boundary由$\theta^TX=0$确定,SVM则用$w^TX+b=0$表示,其中b相当于logistic regression中的$\theta_0$，从形式上看，两者并无区别，当然如前面所说，两者的目标不一样，logistic regression着眼于全局，SVM着眼于support
vectors。有监督算法都有label变量y，logistic
regression取值是&lt;code&gt;{0,1}&lt;/code&gt;，而SVM为了计算距离方便，取值为&lt;code&gt;{-1,1}&lt;/code&gt;。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Five things biologists should know about statistics</title>
      <link>https://guangchuangyu.github.io/2011/06/five-things-biologists-should-know-about-statistics/</link>
      <pubDate>Fri, 24 Jun 2011 06:10:37 +0800</pubDate>
      
      <guid>https://guangchuangyu.github.io/2011/06/five-things-biologists-should-know-about-statistics/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.ebi.ac.uk/~birney/&#34;&gt;Ewan Birney&lt;/a&gt;最近的一篇博文（&lt;a href=&#34;http://genomeinformatician.blogspot.com/2011/06/five-statistical-things-i-wished-i-had.html&#34;&gt;Five statistical things I wished I had been taught 20 years ago&lt;/a&gt;
）讲述了统计对于生物学的重要性。&lt;/p&gt;

&lt;p&gt;一开始从RA Fisher讲起，说生物压根就是统计。Fisher是个农业学家，他所建立的那些统计方法，都是从生物学问题出发。&lt;/p&gt;

&lt;p&gt;Ewan所谈及的五个方面分别是：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;1. Non parametric statistics. These are statistical tests which make a
bare minimum of assumptions of underlying distributions; in biology we
are rarely confident that we know the underlying distribution, and hand
waving about central limit theorem can only get you so far. Wherever
possible you should use a non parameteric test. This is Mann-Whitney (or
Wilcoxon if you prefer) for testing &amp;ldquo;medians&amp;rdquo; (Medians is in quotes
because this is not quite true. They test something which is closely
related to the median) of two distributions, Spearman&amp;rsquo;s Rho (rather
pearson&amp;rsquo;s r2) for correlation, and the Kruskal test rather than ANOVAs
(though if I get this right, you can&amp;rsquo;t in Kruskal do the more
sophisticated nested models you can do with ANOVA). Finally, don&amp;rsquo;t
forget the rather wonderful Kolmogorov-Smirnov (I always think it sounds
like really good vodka) test of whether two sets of observations come
from the same distribution. All of these methods have a basic theme of
doing things on the rank of items in a distribution, not the actual
level. So - if in doubt, do things on the rank of metric, rather than
the metric itself.&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>Bootstrap Method</title>
      <link>https://guangchuangyu.github.io/2009/07/bootstrap-method/</link>
      <pubDate>Fri, 31 Jul 2009 09:14:42 +0800</pubDate>
      
      <guid>https://guangchuangyu.github.io/2009/07/bootstrap-method/</guid>
      <description>&lt;p&gt;[bootstrap](&lt;a href=&#34;http://en.wikipedia.org/wiki/Bootstrapping_(statistics))是对观测数据集进行有放回（replacement）的随机抽样，以评估总体的各项统计指标。可以用于假设检验、参数估计。好处是并不要求大样本，也不要求正态数据，并且对于不同的统计指标使用的是同样的计算方法。结果也更为可靠，坏处是计算量大。&#34;&gt;http://en.wikipedia.org/wiki/Bootstrapping_(statistics))是对观测数据集进行有放回（replacement）的随机抽样，以评估总体的各项统计指标。可以用于假设检验、参数估计。好处是并不要求大样本，也不要求正态数据，并且对于不同的统计指标使用的是同样的计算方法。结果也更为可靠，坏处是计算量大。&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;统计推断(statistical inference)是基于样本统计值的抽样分布来计算的，抽样分布需要从总体中许多的样本来计算，在只有一个样本的情况下，bootstrap对这一随机样本进行有放回的重复抽样，每一个重抽样本与原始随机样本一样大，每次计算相应的抽样的统计值，重复了N次之后，就可以计算统计值的bootstrap分布。&lt;/p&gt;

&lt;p&gt;下面做一个小小的试验：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a &amp;lt;- c(seq(1:10), rnorm(50))  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;#创建一个样本，60个数据，非正态分布的，如下图&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://guangchuangyu.github.io/blog_images/2009/07/sample_a.png&#34; alt=&#34;&#34; title=&#34;sample_a&#34; /&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>从概率的角度看 如何告别单身</title>
      <link>https://guangchuangyu.github.io/2008/08/88-bachelor/</link>
      <pubDate>Tue, 26 Aug 2008 15:10:00 +0800</pubDate>
      
      <guid>https://guangchuangyu.github.io/2008/08/88-bachelor/</guid>
      <description>&lt;p&gt;国家人口统计男人比女人多了3700万，在大学校园里更是流传着“我很丑，可是我很抢手”（女生版）、“我很帅，可是我很无奈”（男生版）。&lt;/p&gt;

&lt;p&gt;鉴于大龄猥琐男越来越盛行，以及小平同志说“让一部分人先恋起来嘛”
今日从科学的角度，让大家明白如何告别单身。
授人与鱼不如授人与渔。即使没能让你奔小康，起码也解决温饱~~~&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://guangchuangyu.github.io/blog_images/2008/11/xx0.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;告别单身的不二法则，三个字，“厚脸皮”，详见下面分析&lt;/p&gt;

&lt;p&gt;如果一个男人追一个女人，成功的概率只有0.2，
那么连续追6个，至少有一个成功的概率，高达0.74&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; 1-0.8^6
[1] 0.737856
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果连续追7个的话，至少一个成功的概率将达到0.79&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; 1-0.8^7
[1] 0.7902848
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果你不是特别差，成功的概率假如是0.3，那么连续追几个的成功概率将更高。。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; 1-0.7^6
[1] 0.882351
&amp;gt; 1-0.7^7
[1] 0.9176457
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
  </channel>
</rss>
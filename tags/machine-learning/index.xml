<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Guangchuang Yu</title>
    <link>https://guangchuangyu.github.io/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on Guangchuang Yu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Apr 2012 05:37:55 +0800</lastBuildDate><atom:link href="https://guangchuangyu.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Support Vector Machine</title>
      <link>https://guangchuangyu.github.io/2012/04/support-vector-machine/</link>
      <pubDate>Thu, 12 Apr 2012 05:37:55 +0800</pubDate>
      
      <guid>https://guangchuangyu.github.io/2012/04/support-vector-machine/</guid>
      <description>&lt;p&gt;支持向量机(Support Vector Machines, SVM)最初由Vladimir
Vapnik于1997年提出，SVM最简单的形式就是找出一下区分界限（descision
boundary），也称之为超平面(hyperplane)，使得离它最近的点（称之为support
vectors）与之间隔最大。
&lt;img src=&#34;http://guangchuangyu.github.io/blog_images/2012/04/linearSVM.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;这和logistic regression有些相似，区别在于logistic
regression要求所有的点尽可能地远离中间那条线，而SVM是要求最接近中间线的点尽可能地远离中间线。也就是说SVM的主要目标是区分那些最难区分的点。&lt;/p&gt;
&lt;p&gt;SVM对于hyperplane的定义，在形式上和logistic regression一样,logistic
regression的decision boundary由$\theta^TX=0$确定,SVM则用$w^TX+b=0$表示,其中b相当于logistic regression中的$\theta_0$，从形式上看，两者并无区别，当然如前面所说，两者的目标不一样，logistic regression着眼于全局，SVM着眼于support
vectors。有监督算法都有label变量y，logistic
regression取值是&lt;code&gt;{0,1}&lt;/code&gt;，而SVM为了计算距离方便，取值为&lt;code&gt;{-1,1}&lt;/code&gt;。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
